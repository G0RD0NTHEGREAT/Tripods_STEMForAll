{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tripods Project 2 - Image Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> In this project we will be finding an image, turning this image into usable data, and then performing various operations on this data to change the features of the image. For a bit of background, images are actually represented in Python as a 3-D matrix of floating point numbers where the dimensions are [height, width, color]. Each (height, width) pair corresponds to a single pixel on your screen and the extra dimension (color) corresponds to one of three values representing either Red, Green, or Blue (or RGB). In essence this means each image is made of 3 different slices of pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 1**  \n",
    "    We will begin by finding an image. Go look up a picture, then save it. I recommend turning your image into a .png file if it isn't already. Next, save it into your Jupyter notebook folder that contains your notebook for this project. We will be using the PIL package to work with these images. The code for this image import will be provided, just change the line of code below from `image = Image.open('spider.png')` to `image = Image.open('your_image.png')`. You can also use the original `spider.png`, it will be provided. The line below `data = np.asarray(image)` is what turns our image file into our 3-D matrix. I recommend looking into the PIL and NumPy API's so you can check out more details about your image. For instance, `data.shape` will be very helpful for this project because it will tell you the dimensions of your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the image.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math as math\n",
    "import cv2\n",
    "\n",
    "image = Image.open('spider.png')\n",
    "data = np.asarray(image)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> This is my picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](spider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 2**   \n",
    "    Make your image grayscale by multiplying the entire R slice (0) by 0.299, the G slice (1) by 0.587, and the B slice by 0.114. Use list compressions to do this without for-loops. Print your image when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> Grayscale Spider-Man  \n",
    "    \n",
    "![alt text](gray_spider2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 3: Convolution Function and Blur**  \n",
    "    In image processing, an important operation is called \"convolution.\" Convolution is a method of filtering and can lead to a bunch of cool effects. The effects we will explore are blur or smooth, sharpen, and edge. Convolution works as in the GIF below. In the GIF, there is a 3x3 filter matrix that scans through the pixels of an image. In each stage of the scan, a mathematical operation takes place which sort of combines information from the image pixels and condenses them into 1 pixel in the new image. The operation can be written as                     \n",
    "    \n",
    "$$\\text{new_pixel}[i,j] = \\sum_{u=0}^{\\text{filter height}} \\sum_{v=0}^{\\text{filter width}} \\text{kernel}[u, v] * \\text{data_padded}[i+u, j+v]$$  \n",
    "    \n",
    "In the above expression, \"kernel\" refers to your filter matrix and \"data_padded\" is your image data that is \"padded\" with 0's around its perimeter. These 0's are necessary for the convolution to work. For convolution to work, the center pixel of your filter must be at some point able to pass over each pixel in your main image, and this padding is what lets that happen (otherwise your filter would go out of bounds). The padding will change depending on the size of your filter. A good rule of thumb is if your filter is NxN, then make your padding $floor(\\frac{n}{2})$ layers thick. Only the height and width of your image matrix needs to be padded. Also, all 3 color channels (slices) need to be convoluted separately. To pad an image, look at the `np.pad` function in NumPy's documentation. \n",
    "    \n",
    "Your task will be to write a function that takes a filter matrix, an image data matrix, and a pad_width as input and returns a new image data matrix by convoluting the filter with the data matrix. There are multiple ways to do this but as a hint, doing this requires 5 nested for-loops if you don't utilize NumPy and only 3 nested for-loops if you do utilize NumPy. Honestly, some of you may know how to make this even more efficient than that, and if you want to go for it! Either way will give you the right answer, but as a heads up the 5 for-loop method is slower than the 3 for-loop method, and depending on how big your filters are, this operation can take a little while for your computer to compute. I recommend trying to first blur or smooth your image with the following filter:\n",
    "    \n",
    "$$ \n",
    "\\frac{1}{9} \\begin{Bmatrix}\n",
    "   1 & 1 & 1 \\\\\n",
    "   1 & 1 & 1 \\\\\n",
    "   1 & 1 & 1\n",
    "  \\end{Bmatrix} \\tag{5}\n",
    "$$\n",
    "    \n",
    "This filter can be generalized to an NxN matrix with 1's in every position and instead of dividing by $\\frac{1}{9}$, you divide by $\\frac{1}{n^2}$. This operation in essence is averaging local pixel values together to produce the blurring effect. Also, I recommend you use the printImage function I wrote that takes in image data as input and then shows the image. This will make things less tedious in testing.\n",
    "\n",
    "![alt text](convolution.gif)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(kernel, data, pad_width):\n",
    "    return(0)\n",
    "    \n",
    "def edge(data):\n",
    "     return(0)\n",
    "    \n",
    "def threshold(data, t):\n",
    "    return(0)\n",
    "    \n",
    "def printImage(data):\n",
    "    data = data.astype(np.uint8)\n",
    "    data_image = Image.fromarray(data)\n",
    "    data_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> This code should make an NxN blur filter and convolutes the image data. If you have trouble seeing the blur effect, try changing your filter size to be bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> Print the blurred image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My blurry Spider-Man. Please note that I used a 15x15 filter to do this, and depending on your implementation this may take some time (like >= 5 minutes). If it is taking a long time for you consider using a 3x3, 5x5, or whatever filter you feel like might be the best for the combination of time and effectiveness.\n",
    "\n",
    "![alt text](blurry_spider.png)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 4**  \n",
    "    Sharpen your image by making a \"mask.\" This is easy to do with the following formulas:  \n",
    "    $$\\text{mask} = \\text{data} - \\text{data_blurred}$$\n",
    "    $$\\text{data_sharp} = \\text{data} + \\text{mask}$$  \n",
    "    \n",
    " <font size = \"3\">  Then print out your sharpened image from the data in $\\text{data_sharp}$. Please note that you need your blurred data for this (the blurrier the better). If you get those weird green pixels, it isn't the end of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My sharpened image (don't mind the green pixels).\n",
    "\n",
    "![alt text](sharp_spider.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 5**  \n",
    "Using the following filters:\n",
    "    \n",
    "$$ \n",
    "K_{x} =\n",
    "\\begin{Bmatrix}\n",
    "    -1 & 0 & 1 \\\\\n",
    "    -2 & 0 & 2 \\\\\n",
    "    -1 & 0 & 1\n",
    "    \\end{Bmatrix}\n",
    "$$\n",
    "  \n",
    ".    \n",
    "    \n",
    "$$ \n",
    "K_{y} =\n",
    "\\begin{Bmatrix}\n",
    "    -1 & -2 & -1 \\\\\n",
    "     0 & 0 & 0 \\\\\n",
    "     1 & 2 & 1\n",
    "    \\end{Bmatrix}\n",
    "$$\n",
    "    \n",
    "And the following formula:\n",
    "    \n",
    "$$E = \\sqrt{(K_{x}*I)^2 + (K_{y}*I)^2}$$\n",
    "\n",
    "Calculate the edged image data matrix $E$, where $I$ is your BLURRED (again the blurrier the better) image data matrix and $*$ means convolution. These matrices $K_{x}$ and $K_{y}$ are the 3x3 horizontal and vertical laplacian operators of an image. If you'd like to learn more about the theory of how this works, this is a good resource: https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm. \n",
    "    \n",
    "A problem that will arise is that the resulting image will be too dark to see anything. To fix this, write a \"threshold\" function that scans through each pixel of $E$ and sets the pixel value to be 255 if the pixel value is greater than some number $t$, and set the pixel value to be $0$ otherwise. This scanning must be done for all 3 color channels. You also may have to play around with your value of $t$, personally I used $t = 12$.\n",
    "    \n",
    "When complete, print your image. It should look vauguely similar to the image I provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My edged image.\n",
    "\n",
    "![alt text](edge_spider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations for finishing!\n",
    "\n",
    "![alt text](smiley.png)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
