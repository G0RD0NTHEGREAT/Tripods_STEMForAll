{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tripods Project 2 - Image Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> In this project we will be finding an image, turning this image into usable data, and then performing various operations on this data to change the features of the image. For a bit of background, images are actually represented in Python as a 3-D matrix of floating point numbers where the dimensions are [height, width, color]. Each (height, width) pair corresponds to a single pixel on your screen and the extra dimension (color) corresponds to one of three values representing either Red, Green, or Blue (or RGB). In essence this means each image is made of 3 different slices of pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 1**  \n",
    "    We will begin by finding an image. Go look up a picture, then save it. I recommend turning your image into a .png file if it isn't already. Next, save it into your Jupyter notebook folder that contains your notebook for this project. We will be using the PIL package to work with these images. The code for this image import will be provided, just change the line of code below from `image = Image.open('spider.png')` to `image = Image.open('your_image.png')`. You can also use the original `spider.png`, it will be provided. The line below `data = np.asarray(image)` is what turns our image file into our 3-D matrix. I recommend looking into the PIL and NumPy API's so you can check out more details about your image. For instance, `data.shape` will be very helpful for this project because it will tell you the dimensions of your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the image.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math as math\n",
    "\n",
    "image = Image.open('spider.png')\n",
    "data = np.asarray(image)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> This is my picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](spider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 2**   \n",
    "    Make your image grayscale by multiplying the entire R slice (0) by 0.299, the G slice (1) by 0.587, and the B slice by 0.114. Use list compressions to do this without for-loops. Print your image when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the image grayscale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> Grayscale Spider-Man  \n",
    "    \n",
    "![alt text](gray_spider2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 3: Convolution Function and Blur**  \n",
    "    In image processing, an important operation is called \"convolution.\" Convolution is a method of filtering and can lead to a bunch of cool effects. The effects we will explore are blur or smooth, sharpen, and edge. Convolution works as in the GIF below. In the GIF, there is a 3x3 filter matrix that scans through the pixels of an image. In each stage of the scan, a mathematical operation takes place which sort of combines information from the image pixels and condenses them into 1 pixel in the new image. The operation can be written as                     \n",
    "    \n",
    "$$\\text{new_pixel}[i,j] = \\sum_{u=0}^{\\text{filter height}} \\sum_{v=0}^{\\text{filter width}} \\text{kernel}[u, v] * \\text{data_padded}[i+u, j+v]$$  \n",
    "    \n",
    "In the above expression, \"kernel\" refers to your filter matrix and \"data_padded\" is your image data that is \"padded\" with 0's around its perimeter. These 0's are necessary for the convolution to work. Also for convolution to work, the center pixel of your filter must be able to pass over each pixel in your main image, and this padding is what lets that happen (otherwise your filter would go out of bounds). The padding will change depending on the size of your filter. A good rule of thumb is if your filter is NxN, then make your padding $floor(\\frac{n}{2})$ layers thick. Only the height and width of your image matrix needs to be padded. Also, all 3 color channels (slices) need to be convoluted separately. To pad an image, look at the `np.pad` function in NumPy's documentation. The padding is represented by the empty pixels in the GIF below.\n",
    "    \n",
    "Your task will be to write a function that takes a filter matrix, an image data matrix, and a pad_width as input and returns a new image data matrix by convoluting the filter with the data matrix. There are multiple ways to do this but as a hint, doing this naively will require 5 nested for-loops if you don't utilize NumPy and only 3 nested for-loops if you do utilize NumPy (specifically the `np.sum` function). Honestly some of you may know how to make this even more efficient than that, and if you want to go for it! Either way will give you the right answer, but as a heads up the 5 for-loop method is MUCH slower than the 3 for-loop method, and depending on how big your filters are, this operation can take a little while for your computer to compute. I recommend trying to first blur or smooth your image with the following filter:\n",
    "    \n",
    "$$ \n",
    "\\frac{1}{9} \\begin{Bmatrix}\n",
    "   1 & 1 & 1 \\\\\n",
    "   1 & 1 & 1 \\\\\n",
    "   1 & 1 & 1\n",
    "  \\end{Bmatrix} \\tag{5}\n",
    "$$\n",
    "    \n",
    "This filter can be generalized to an NxN matrix with 1's in every position and instead of dividing by $\\frac{1}{9}$, you divide by $\\frac{1}{N^2}$. This operation in essence is averaging local pixel values together to produce the blurring effect. Also, I wrote a function called `printImage` for you that takes in image data as input and then shows the image. This will make things less tedious in testing.\n",
    "\n",
    "![alt text](convolution.gif)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Don't forget to change the return statements!\n",
    "\n",
    "def convolute(kernel, data, pad_width):\n",
    "    # Make a padded data matrix.\n",
    "    \n",
    "    # for each color channel\n",
    "        # for each row of pixels\n",
    "            # for each column of pixels\n",
    "                # perform convolution calculation from above\n",
    "                \n",
    "    return(0)\n",
    "\n",
    "def edge(data):\n",
    "    \n",
    "    # Make K_xfilter\n",
    "    # Make K_yfilter\n",
    "    # Perform the convolutions/calculations according to the equation for E\n",
    "    \n",
    "    return(0)\n",
    "\n",
    "def threshold(data, t):\n",
    "    \n",
    "    # for each color channel\n",
    "        # for each row of pixels\n",
    "            # for each column of pixels\n",
    "                # if pixel value > t\n",
    "                    # your code here\n",
    "                # else\n",
    "                    # your code here\n",
    "                    \n",
    "    return(0)\n",
    "    \n",
    "def printImage(data):\n",
    "    data = data.astype(np.uint8)\n",
    "    data_image = Image.fromarray(data)\n",
    "    data_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> This code makes an NxN blur filter and convolutes the image data. If you have trouble seeing the blur effect, try changing your filter size to be bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Blur setup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> Prints blurred image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print blurred image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My blurry Spider-Man. Please note that I used a 15x15 filter to do this, and depending on your implementation this may take some time (like >= 5 minutes for the 5 for-loop implementation and 5 seconds for the 3 for-loop implementation). If it is taking a long time for you consider using a smaller filter.  \n",
    "\n",
    "![alt text](blurry_spider.png)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 4**  \n",
    "    Sharpen your image by making a \"mask.\" This is easy to do with the following formulas:  \n",
    "    $$\\text{mask} = \\text{data} - \\text{data_blurred}$$\n",
    "    $$\\text{data_sharp} = \\text{data} + \\text{mask}$$  \n",
    "    \n",
    " <font size = \"3\">  Print out your sharpened image from the data in $\\text{data_sharp}$. Please note that you need your blurred data for this (the blurrier the better). If you get those weird green pixels, it isn't the end of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sharpen and print sharpened image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My sharpened image (don't mind the green pixels).\n",
    "\n",
    "![alt text](sharp_spider.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"> **Task 5**  \n",
    "Using the following filters:\n",
    "    \n",
    "$$ \n",
    "K_{x} =\n",
    "\\begin{Bmatrix}\n",
    "    -1 & 0 & 1 \\\\\n",
    "    -2 & 0 & 2 \\\\\n",
    "    -1 & 0 & 1\n",
    "    \\end{Bmatrix}\n",
    "$$\n",
    "  \n",
    ".    \n",
    "    \n",
    "$$ \n",
    "K_{y} =\n",
    "\\begin{Bmatrix}\n",
    "    -1 & -2 & -1 \\\\\n",
    "     0 & 0 & 0 \\\\\n",
    "     1 & 2 & 1\n",
    "    \\end{Bmatrix}\n",
    "$$\n",
    "    \n",
    "And the following formula:\n",
    "    \n",
    "$$E = \\sqrt{(K_{x}*I)^2 + (K_{y}*I)^2}$$\n",
    "\n",
    "Calculate the edged image data matrix $E$, where $I$ is your BLURRED image data matrix (again the blurrier the better)and $*$ means convolution. These matrices $K_{x}$ and $K_{y}$ are the 3x3 horizontal and vertical laplacian operators of an image. If you'd like to learn more about the theory of how this works, this is a good resource: https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm. \n",
    "    \n",
    "A problem that will arise is that the resulting image will be too dark to see anything. To fix this, write a \"threshold\" function that scans through each pixel of $E$ and sets the pixel value to be 255 if the pixel value is greater than some number $t$, and set the pixel value to be $0$ otherwise. Just do this scanning over one of the color channels, this will be good enough. Just make sure to set the other channels' values to 0. If done correctly you should see the edges of your image in one single color. You also may have to play around with your value of $t$, personally I used $t = 15$.\n",
    "    \n",
    "When complete, print your image. It should look vaguely similar to the image I provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get edge data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edge threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print edged image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My edged image.\n",
    "\n",
    "![alt text](edge_spider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations for finishing!\n",
    "\n",
    "![alt text](smiley.png)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
